<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Papers relevant to Video Prediction | Enjoy Short Life</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Unsupervised Learning for Physical Interaction through Video Prediction Develop a predictive model which merges appearance infromation from previous frames with">
<meta property="og:type" content="article">
<meta property="og:title" content="Papers relevant to Video Prediction">
<meta property="og:url" content="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/index.html">
<meta property="og:site_name" content="Enjoy Short Life">
<meta property="og:description" content="Unsupervised Learning for Physical Interaction through Video Prediction Develop a predictive model which merges appearance infromation from previous frames with motion predicted by the model. This pap">
<meta property="og:image" content="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/content/images/2018/1/MCNet_Framework.png">
<meta property="og:image" content="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/content/images/2018/1/forward_prediction.png">
<meta property="og:image" content="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/content/images/2018/1/samevideo.png">
<meta property="og:image" content="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/content/images/2018/1/encoder_decoder.png">
<meta property="og:updated_time" content="2018-01-27T09:33:30.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Papers relevant to Video Prediction">
<meta name="twitter:description" content="Unsupervised Learning for Physical Interaction through Video Prediction Develop a predictive model which merges appearance infromation from previous frames with motion predicted by the model. This pap">
<meta name="twitter:image" content="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/content/images/2018/1/MCNet_Framework.png">
  
    <link rel="alternate" href="/atom.xml" title="Enjoy Short Life" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Enjoy Short Life</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://sunyasheng.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Papers-relevant-to-Video-Prediction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/16/Papers-relevant-to-Video-Prediction/" class="article-date">
  <time datetime="2018-01-16T05:17:24.000Z" itemprop="datePublished">2018-01-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Papers relevant to Video Prediction
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Unsupervised-Learning-for-Physical-Interaction-through-Video-Prediction"><a href="#Unsupervised-Learning-for-Physical-Interaction-through-Video-Prediction" class="headerlink" title="Unsupervised Learning for Physical Interaction through Video Prediction"></a>Unsupervised Learning for Physical Interaction through Video Prediction</h2><ul>
<li>Develop a predictive model which merges appearance infromation from previous frames with motion predicted by the model.</li>
<li>This paper proposes three models, including DNA, CDNA and STP. </li>
<li>The construction of this network is pretty classical.</li>
</ul>
<h2 id="Deep-Multi-Scale-Video-Prediction-Beyond-Mean-Square-Error"><a href="#Deep-Multi-Scale-Video-Prediction-Beyond-Mean-Square-Error" class="headerlink" title="Deep Multi-Scale Video Prediction Beyond Mean Square Error"></a>Deep Multi-Scale Video Prediction Beyond Mean Square Error</h2><ul>
<li>Introduce a network to predict the difference between real $Y_{k}$ and $u(Y_{k-1})$ from $X_{k}$ and a coarse guess of $Y_{k}$</li>
<li>Usually, “ Using $l_{2}$ loss, and to a lesser extent $l_{1}$, produces blurry predictions, increasingly worse when predicting further in the future. “</li>
<li>“Convolutions only aacount for short-range dependencies, limited by the size of their kernels.” But pooling will lead to loss of resolution. There are two methods to tackle this problem. One is using many convolution layers without pooling and the other is “skip” connection to skip the pooling-unpooling pairs and preserve the high frequency information.</li>
</ul>
<h2 id="Decomposing-Motion-and-Content-for-Natural-Video-Sequence-Prediction"><a href="#Decomposing-Motion-and-Content-for-Natural-Video-Sequence-Prediction" class="headerlink" title="Decomposing Motion and Content for Natural Video Sequence Prediction"></a>Decomposing Motion and Content for Natural Video Sequence Prediction</h2><p>This paper proposes MCNet in which the video is decomposed to motion and content part. Many latest technique is introduced in this model.<br>  <img src="content/images/2018/1/MCNet_Framework.png" alt="Fig.1. Forward Prediction" style="width: 600px;"> </p>
<h2 id="Unsupervised-Learning-of-Disentangled-Representation-from-Video"><a href="#Unsupervised-Learning-of-Disentangled-Representation-from-Video" class="headerlink" title="Unsupervised Learning of Disentangled Representation from Video"></a>Unsupervised Learning of Disentangled Representation from Video</h2><p>This paper proposes a new model DRNET that learns disentangled image representations from video. This approch factorizes each frame into a stationary part and a temporally varying component. </p>
<ul>
<li><p>Basically, this framework extracts the content(stationary) and pose(dynamic) part explicitly.</p>
</li>
<li><p>The core idea is to explore an efficient way to represent content and pose respectively, which can be stated to train a encoder and decoder. </p>
</li>
<li><p>Generating future frames by recurrently predicting the pose vector $h_{p}$, as is shown below.</p>
<p><img src="content/images/2018/1/forward_prediction.png" alt="Fig.1. Forward Prediction" style="width: 800px;"> </p>
</li>
<li><p>The adversarial loss is introduced to exploit the fact that the objects do not typically change within a video, but they do between different videos.</p>
<p><img src="content/images/2018/1/samevideo.png" alt="Fig.1. Ensure Same Video" style="width: 600px;"> </p>
</li>
<li><p>Similarity loss, reconstruction loss and adversarial loss are introduce to train the pose encoder and content encoder.</p>
<p><img src="content/images/2018/1/encoder_decoder.png" alt="Fig.1. Encoder and Decoder Loss" style="width: 600px;"> </p>
</li>
</ul>
<h2 id="Unsupervised-Learning-of-Video-Representations-using-LSTMs"><a href="#Unsupervised-Learning-of-Video-Representations-using-LSTMs" class="headerlink" title="Unsupervised Learning of Video Representations using LSTMs"></a>Unsupervised Learning of Video Representations using LSTMs</h2><ul>
<li>This paper gives us an intuition about LSTM antoencoder model.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sunyasheng.github.io/2018/01/16/Papers-relevant-to-Video-Prediction/" data-id="cjhzn73eu000fv0s66nifenqh" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/01/16/Frequently-Used-Commands-in-Windows/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Frequently Used Commands in Windows
        
      </div>
    </a>
  
  
    <a href="/2018/01/16/Details-of-Neural-Network/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Details of Deep Learning</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/21/Byesian-Summary/">Summary of Byesian Theory</a>
          </li>
        
          <li>
            <a href="/2018/03/18/Torch-Tutorial/">Torch_Tutorial</a>
          </li>
        
          <li>
            <a href="/2018/03/04/GAN-Workflow/">GAN Workflow</a>
          </li>
        
          <li>
            <a href="/2018/02/04/Introduction-of-Pascal-VOC-Dataset/">Introduction of Pascal VOC Dataset</a>
          </li>
        
          <li>
            <a href="/2018/02/04/Frequently-Used-Script/">Frequently Used Script</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  
	<!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": { 
        preferredFont: "TeX", 
        availableFonts: ["STIX","TeX"], 
        linebreaks: { automatic:true }, 
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) 
    },
    tex2jax: { 
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ], 
        processEscapes: true, 
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {  
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, 
        Macros: { href: "{}" } 
    },
    messageStyle: "none"
    }); 
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Yasheng Sun<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>